{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/work/04233/sw33286/AIDA-SCRIPTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.contrib.layers import safe_embedding_lookup_sparse as embedding_lookup_unique\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = ['one','two','three','four','five',\n",
    "         'six','seven','eight','nine','ten']\n",
    "FROM_LEN = 3\n",
    "TO_LEN = 8\n",
    "\n",
    "indexer = helpers.Indexer()\n",
    "indexer.get_index('PAD')\n",
    "indexer.get_index('EOS')\n",
    "for word in VOCAB:\n",
    "    indexer.get_index(word)\n",
    "    \n",
    "def generate_sent(from_len, to_len):\n",
    "    length = np.random.randint(from_len, to_len)\n",
    "    return np.random.choice(VOCAB, length)\n",
    "\n",
    "def to_code(sent):\n",
    "    return [indexer.get_index(word) for word in sent]\n",
    "\n",
    "def to_sent(code):\n",
    "    return list(map(lambda w_idx:indexer.get_object(w_idx), code))\n",
    "    \n",
    "def get_batch(n, from_len=FROM_LEN, to_len=TO_LEN):\n",
    "    return [to_code(generate_sent(from_len,to_len)) for _ in range(n)]\n",
    "\n",
    "class DataIterator:\n",
    "    \n",
    "    def __init__(self, X, Y, shuf=False):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.size = len(self.X)\n",
    "        self.indices = list(range(self.size))\n",
    "        self.cursor = 0\n",
    "        self.epoch = 0\n",
    "        self.shuf = shuf\n",
    "    \n",
    "    def _shuffle(self):\n",
    "        random.shuffle(self.indices)\n",
    "        self.X = self.X[self.indices]\n",
    "        self.Y = self.Y[self.indices]\n",
    "    \n",
    "    def next_batch(self, k):\n",
    "        if self.cursor+k >= self.size:\n",
    "            batch_X, batch_Y = self.X[self.cursor:], self.Y[self.cursor:]\n",
    "            self.cursor = 0\n",
    "            self.epoch += 1\n",
    "            self._shuffle()\n",
    "        else:\n",
    "            batch_X, batch_Y = self.X[self.cursor:self.cursor+k], self.Y[self.cursor:self.cursor+k]\n",
    "            self.cursor += k\n",
    "        return batch_X, batch_Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(get_batch(10000))\n",
    "test_data = np.array(get_batch(200))\n",
    "train_iter = DataIterator(train_data, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PtrNet:\n",
    "    \n",
    "    def __init__(self, cell_size, \n",
    "                       embedding_size=50,\n",
    "                       glove_embeddings=False,\n",
    "                       learning_rate=1e-4,\n",
    "                       bidirectional=True, \n",
    "                       attention=True):\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        self.attention = attention\n",
    "        self.cell_size = cell_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.glove_embeddings = glove_embeddings\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def _build_graph(self, enc_in_name, enc_in_len_name, dec_tar_name,\n",
    "                           embedding_scope_name, embedding_name,\n",
    "                           encoder_scope_name, decoder_scope_name):\n",
    "        \n",
    "        # init LSTM cells\n",
    "        self._init_cells()\n",
    "        # init placeholders\n",
    "        self._init_placeholders(enc_in_name, enc_in_len_name, dec_tar_name)\n",
    "        # init embeddings\n",
    "        self._init_embeddings(embedding_scope_name, embedding_name)\n",
    "        # build encoder\n",
    "        self._build_encoder(encoder_scope_name)\n",
    "        # build decoder\n",
    "        self._build_decoder(decoder_scope_name)\n",
    "        # build optimizer\n",
    "        self._build_optimizer()\n",
    "        self._build_evaluator()\n",
    "        \n",
    "        \n",
    "    def _init_cells(self):\n",
    "        \n",
    "        self.encoder_cell = LSTMCell(self.cell_size)\n",
    "        if self.bidirectional:\n",
    "            self.decoder_cell = LSTMCell(self.cell_size*2)\n",
    "        else:\n",
    "            self.decoder_cell = LSTMCell(self.cell_size)\n",
    "        \n",
    "    def _init_placeholders(self, enc_in_name, enc_in_len_name, dec_tar_name):\n",
    "        \n",
    "        self.encoder_inputs = tf.placeholder(tf.int32, [None, None], name=enc_in_name)\n",
    "        self.encoder_inputs_length = tf.placeholder(tf.int32, [None,], name=enc_in_len_name)\n",
    "        self.decoder_targets = tf.placeholder(tf.int32, [None, None], name=dec_tar_name)\n",
    "        \n",
    "    def _init_embeddings(self, scope_name, embedding_name):\n",
    "        \n",
    "        with tf.variable_scope(scope_name) as scope:\n",
    "            if self.glove_embeddings:\n",
    "                self.embedding_matrix = tf.get_variable(embedding_name, self.glove_embeddings.shape,\n",
    "                                                        initializer=tf.constant_initializer())\n",
    "                glove_feed = tf.placeholder(tf.float32, self.glove_embeddings.shape)\n",
    "                glove_init = self.embedding_matrix.assign(glove_feed)\n",
    "                self.encoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.encoder_inputs)\n",
    "            else:\n",
    "                self.embedding_matrix = tf.get_variable(embedding_name, [self.vocab_size, self.embedding_size],\n",
    "                                                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "                self.encoder_inputs_embedded = tf.nn.embedding_lookup(self.embedding_matrix, self.encoder_inputs)\n",
    "        \n",
    "    def _build_encoder(self, scope_name):\n",
    "        \n",
    "        with tf.variable_scope(scope_name) as scope:\n",
    "            if self.bidirectional:\n",
    "                ((encoder_fw_outputs,encoder_bw_outputs),\n",
    "                 (encoder_fw_final_state,encoder_bw_final_state)) = (\n",
    "                    tf.nn.bidirectional_dynamic_rnn(cell_fw=self.encoder_cell,\n",
    "                                                    cell_bw=self.encoder_cell,\n",
    "                                                    inputs=self.encoder_inputs_embedded,\n",
    "                                                    sequence_length=self.encoder_inputs_length,\n",
    "                                                    dtype=tf.float32, time_major=True)\n",
    "                )\n",
    "                self.encoder_outputs = tf.concat((encoder_fw_outputs,encoder_bw_outputs), 2)\n",
    "                encoder_final_state_c = tf.concat((encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "                encoder_final_state_h = tf.concat((encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "                self.encoder_final_state = LSTMStateTuple(c=encoder_final_state_c, h=encoder_final_state_h)\n",
    "            else:\n",
    "                (self.encoder_outputs,self.encoder_final_state) = (\n",
    "                    tf.nn.dynamic_rnn(cell=self.encoder_cell,\n",
    "                                      inputs=self.encoder_inputs_embedded,\n",
    "                                      sequence_length=self.encoder_inputs_length,\n",
    "                                      dtype=tf.float32, time_major=True)\n",
    "                )\n",
    "                \n",
    "    def _build_decoder(self, scope_name):\n",
    "        \n",
    "        with tf.variable_scope(scope_name) as scope:\n",
    "            encoder_max_time, batch_size = tf.unstack(tf.shape(self.encoder_inputs))\n",
    "            self.decoder_length = self.encoder_inputs_length\n",
    "            self.W = tf.get_variable('W', [self.decoder_cell.output_size, self.vocab_size],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.b = tf.get_variable('b', [self.vocab_size],\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.eos_step_embedded = tf.ones([batch_size, self.decoder_cell.output_size], \n",
    "                                             dtype=tf.float32, name='EOS')\n",
    "            self.pad_step_embedded = tf.zeros([batch_size, self.decoder_cell.output_size], \n",
    "                                              dtype=tf.float32, name='PAD')\n",
    "            self.W1 = tf.get_variable('W1', [self.decoder_cell.output_size, self.decoder_cell.output_size],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.W2 = tf.get_variable('W2', [self.decoder_cell.output_size, self.decoder_cell.output_size],\n",
    "                                      initializer=tf.contrib.layers.xavier_initializer()) \n",
    "            self.v = tf.get_variable('v', [self.decoder_cell.output_size, 1], dtype=tf.float32,\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer())            \n",
    "        \n",
    "        def loop_fn_initial():\n",
    "            initial_elements_finished = (0 >= self.decoder_length)\n",
    "            initial_input = self.eos_step_embedded\n",
    "            initial_cell_state = self.encoder_final_state\n",
    "            initial_cell_output = None \n",
    "            initial_loop_state = None \n",
    "            return (initial_elements_finished,\n",
    "                    initial_input,\n",
    "                    initial_cell_state,\n",
    "                    initial_cell_output,\n",
    "                    initial_loop_state)  \n",
    "        \n",
    "        def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "            def get_next_input():\n",
    "                mt, bc, hd = tf.unstack(tf.shape(self.encoder_outputs))\n",
    "                EW1 = tf.reshape(tf.tensordot(self.encoder_outputs, self.W1, axes=[[2],[0]]),\n",
    "                                 [mt, bc, self.decoder_cell.output_size])\n",
    "                DW2 = tf.matmul(previous_output, self.W2)\n",
    "                EW1_plus_DW2 = tf.add(EW1, DW2)\n",
    "                attention_mat = tf.nn.softmax(tf.reshape(tf.squeeze(tf.tensordot(tf.nn.tanh(EW1_plus_DW2), \n",
    "                                                                                 self.v, \n",
    "                                                                                 axes=[[2],[0]]),\n",
    "                                                                    axis=2), [mt,bc]), dim=0)\n",
    "                selector = tf.one_hot(tf.argmax(attention_mat, axis=0), depth=mt,\n",
    "                                      on_value=1.0, off_value=0.0, axis=0)\n",
    "                inputs_embedded_selected = tf.transpose(tf.multiply(tf.transpose(self.encoder_outputs, [2,0,1]),\n",
    "                                                                    selector), [1,2,0])\n",
    "                next_input = tf.reduce_sum(tf.reshape(inputs_embedded_selected, \n",
    "                                                      [mt,bc,self.decoder_cell.output_size]), axis=0)\n",
    "                return next_input\n",
    "            elements_finished = (time >= self.decoder_length)\n",
    "            finished = tf.reduce_all(elements_finished)\n",
    "            inpt = tf.cond(finished, lambda: self.pad_step_embedded, get_next_input)\n",
    "            state = previous_state\n",
    "            output = previous_output\n",
    "            loop_state = None\n",
    "            return (elements_finished,\n",
    "                    inpt,\n",
    "                    state,\n",
    "                    output,\n",
    "                    loop_state)\n",
    "        \n",
    "        def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "            if previous_state is None:\n",
    "                assert previous_output is None and previous_state is None\n",
    "                return loop_fn_initial()\n",
    "            else:\n",
    "                return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "            \n",
    "        decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(self.decoder_cell, loop_fn)\n",
    "        decoder_outputs = decoder_outputs_ta.stack()\n",
    "        decoder_max_step, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "        decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, self.decoder_cell.output_size))\n",
    "        decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, self.W), self.b)\n",
    "        self.decoder_logits = tf.reshape(decoder_logits_flat, \n",
    "                                         (decoder_max_step, decoder_batch_size, self.vocab_size))\n",
    "        self.decoder_prediction = tf.cast(tf.argmax(self.decoder_logits, 2), dtype=tf.int32)\n",
    "        \n",
    "    def _build_optimizer(self):\n",
    "        \n",
    "        stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.one_hot(self.decoder_targets, depth=self.vocab_size, dtype=tf.float32),\n",
    "            logits=self.decoder_logits\n",
    "        )\n",
    "        self.loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        grads_and_vars = optimizer.compute_gradients(self.loss)\n",
    "        self.train_op = optimizer.apply_gradients(grads_and_vars, self.global_step)\n",
    "        \n",
    "    def _build_evaluator(self):\n",
    "        \n",
    "        correct_raw = tf.cast(tf.equal(self.decoder_prediction, self.decoder_targets), tf.int32)\n",
    "        mask = tf.cast(tf.not_equal(self.decoder_targets, 0), tf.int32)\n",
    "        total_length = tf.cast(tf.reduce_sum(self.encoder_inputs_length), tf.float32)\n",
    "        correct = tf.multiply(correct_raw, mask)\n",
    "        self.accuracy = tf.cast(tf.reduce_sum(correct), tf.float32) / total_length\n",
    "    \n",
    "    def fit(self, train_iter, indexer, \n",
    "            num_epochs, batch_size, verbose=100,\n",
    "            enc_in_name='encoder_inputs',\n",
    "            enc_in_len_name='encoder_inputs_length',\n",
    "            dec_tar_name='decoder_targets',\n",
    "            embedding_scope_name='Embeddings',\n",
    "            embedding_name='embedding_matrix',\n",
    "            encoder_scope_name='Encoder',\n",
    "            decoder_scope_name='Decoder'):\n",
    "        \n",
    "        self.indexer = indexer\n",
    "        self.vocab_size = len(indexer)\n",
    "        tf.reset_default_graph()\n",
    "        self.sess = tf.Session()\n",
    "        self._build_graph(enc_in_name, enc_in_len_name, dec_tar_name,\n",
    "                          embedding_scope_name, embedding_name,\n",
    "                          encoder_scope_name, decoder_scope_name)  \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def to_sent(code):\n",
    "            return list(map(lambda w_idx:indexer.get_object(w_idx), code))        \n",
    "        \n",
    "        curr_epoch = -1\n",
    "        try:\n",
    "            while train_iter.epoch<num_epochs:\n",
    "                if curr_epoch<train_iter.epoch:\n",
    "                    print('Epoch {}:\\n'.format(train_iter.epoch+1))\n",
    "                    curr_epoch += 1\n",
    "                batch_X, batch_Y = train_iter.next_batch(batch_size)\n",
    "                inputs_, inputs_length_ = helpers.batch(batch_X)\n",
    "                targets_, _ = helpers.batch(batch_Y) # target length doesn't matter.\n",
    "                fd = {\n",
    "                    self.encoder_inputs: inputs_,\n",
    "                    self.encoder_inputs_length: inputs_length_,\n",
    "                    self.decoder_targets: targets_\n",
    "                }\n",
    "                _, l, a, step = self.sess.run([self.train_op, self.loss, self.accuracy, self.global_step], fd)\n",
    "                if step==0 or step%verbose==0:\n",
    "                    print('batch {}'.format(step))\n",
    "                    print('  minibatch loss = {} | accuracy = {}'.format(l, a))\n",
    "                    for i,(e_in, dt_pred) in enumerate(zip(\n",
    "                        inputs_.T, # [max-time,batch_size] -> [batch_size,max-time]\n",
    "                        self.sess.run(self.decoder_prediction, fd).T\n",
    "                    )):                    \n",
    "                        print('  sample {}:'.format(i+1))\n",
    "                        print('    enc input           > {}'.format([w for w in to_sent(e_in) if w!='PAD']))\n",
    "                        print('    dec train predicted > {}'.format([w for w in to_sent(dt_pred) if w!='PAD']))\n",
    "                        if i>=2:\n",
    "                            break\n",
    "                    print('\\n')  \n",
    "        except KeyboardInterrupt:\n",
    "            print('training interrupted')\n",
    "    \n",
    "    def evaluate(self, test):\n",
    "        inputs_, inputs_length_ = helpers.batch(test)\n",
    "        targets_, _ = helpers.batch(test)\n",
    "        fd = {\n",
    "            self.encoder_inputs: inputs_,\n",
    "            self.encoder_inputs_length: inputs_length_,\n",
    "            self.decoder_targets: targets_\n",
    "        }    \n",
    "        l, a = self.sess.run([self.loss, self.accuracy], fd)\n",
    "        print('Evaluating on test: loss = {} | accuracy = {}'.format(l,a))\n",
    "    \n",
    "    def end_session(self):\n",
    "        try:\n",
    "            self.sess.close()\n",
    "            print('Session ended.')\n",
    "        except:\n",
    "            print('Attempting to close a closed session or session does not exist.')\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PtrNet(cell_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss = 1.928040862083435 | accuracy = 0.40816327929496765\n",
      "  sample 1:\n",
      "    enc input           > ['four', 'seven', 'ten', 'five']\n",
      "    dec train predicted > ['four', 'seven', 'seven', 'seven', 'five', 'five', 'five']\n",
      "  sample 2:\n",
      "    enc input           > ['six', 'ten', 'ten', 'nine', 'four']\n",
      "    dec train predicted > ['ten', 'ten', 'ten', 'ten', 'ten', 'five', 'five']\n",
      "  sample 3:\n",
      "    enc input           > ['eight', 'six', 'two', 'ten', 'ten', 'four']\n",
      "    dec train predicted > ['ten', 'ten', 'ten', 'ten', 'ten', 'ten', 'five']\n",
      "\n",
      "\n",
      "Epoch 2:\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss = 1.7469537258148193 | accuracy = 0.4000000059604645\n",
      "  sample 1:\n",
      "    enc input           > ['five', 'seven', 'seven', 'one', 'four', 'four']\n",
      "    dec train predicted > ['seven', 'four', 'four', 'four', 'four', 'seven']\n",
      "  sample 2:\n",
      "    enc input           > ['nine', 'five', 'nine', 'five', 'eight', 'eight', 'three']\n",
      "    dec train predicted > ['nine', 'five', 'eight', 'eight', 'eight', 'eight', 'eight']\n",
      "  sample 3:\n",
      "    enc input           > ['two', 'nine', 'eight']\n",
      "    dec train predicted > ['two', 'nine', 'nine']\n",
      "\n",
      "\n",
      "Epoch 3:\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss = 1.6289294958114624 | accuracy = 0.47826087474823\n",
      "  sample 1:\n",
      "    enc input           > ['one', 'five', 'four', 'seven']\n",
      "    dec train predicted > ['one', 'five', 'five', 'seven']\n",
      "  sample 2:\n",
      "    enc input           > ['two', 'six', 'nine', 'eight', 'two', 'eight', 'five']\n",
      "    dec train predicted > ['two', 'two', 'eight', 'eight', 'eight', 'eight', 'eight']\n",
      "  sample 3:\n",
      "    enc input           > ['five', 'three', 'seven']\n",
      "    dec train predicted > ['three', 'five', 'five']\n",
      "\n",
      "\n",
      "Epoch 4:\n",
      "\n",
      "batch 4000\n",
      "  minibatch loss = 1.5107898712158203 | accuracy = 0.4423076808452606\n",
      "  sample 1:\n",
      "    enc input           > ['eight', 'one', 'eight', 'five', 'one', 'eight', 'nine']\n",
      "    dec train predicted > ['eight', 'eight', 'eight', 'eight', 'eight', 'eight', 'nine']\n",
      "  sample 2:\n",
      "    enc input           > ['nine', 'two', 'nine', 'ten', 'six']\n",
      "    dec train predicted > ['nine', 'nine', 'nine', 'nine', 'six']\n",
      "  sample 3:\n",
      "    enc input           > ['three', 'one', 'eight']\n",
      "    dec train predicted > ['three', 'three', 'one']\n",
      "\n",
      "\n",
      "Epoch 5:\n",
      "\n",
      "batch 5000\n",
      "  minibatch loss = 1.3886654376983643 | accuracy = 0.4285714328289032\n",
      "  sample 1:\n",
      "    enc input           > ['nine', 'six', 'five', 'four']\n",
      "    dec train predicted > ['nine', 'nine', 'five', 'five']\n",
      "  sample 2:\n",
      "    enc input           > ['ten', 'seven', 'ten', 'four', 'ten']\n",
      "    dec train predicted > ['ten', 'ten', 'ten', 'ten', 'ten']\n",
      "  sample 3:\n",
      "    enc input           > ['one', 'three', 'five', 'nine', 'three', 'five', 'three']\n",
      "    dec train predicted > ['three', 'three', 'three', 'three', 'three', 'three', 'three']\n",
      "\n",
      "\n",
      "Epoch 6:\n",
      "\n",
      "batch 6000\n",
      "  minibatch loss = 1.3500404357910156 | accuracy = 0.5306122303009033\n",
      "  sample 1:\n",
      "    enc input           > ['eight', 'four', 'three', 'four', 'one']\n",
      "    dec train predicted > ['four', 'four', 'four', 'four', 'four']\n",
      "  sample 2:\n",
      "    enc input           > ['two', 'nine', 'two']\n",
      "    dec train predicted > ['two', 'two', 'two']\n",
      "  sample 3:\n",
      "    enc input           > ['four', 'four', 'ten', 'five']\n",
      "    dec train predicted > ['four', 'four', 'four', 'ten']\n",
      "\n",
      "\n",
      "Epoch 7:\n",
      "\n",
      "batch 7000\n",
      "  minibatch loss = 1.1900455951690674 | accuracy = 0.6000000238418579\n",
      "  sample 1:\n",
      "    enc input           > ['six', 'six', 'three', 'two', 'four']\n",
      "    dec train predicted > ['six', 'six', 'two', 'two', 'four']\n",
      "  sample 2:\n",
      "    enc input           > ['ten', 'seven', 'five', 'ten', 'seven', 'two', 'seven']\n",
      "    dec train predicted > ['ten', 'ten', 'seven', 'seven', 'seven', 'seven', 'two']\n",
      "  sample 3:\n",
      "    enc input           > ['three', 'one', 'eight', 'one', 'four']\n",
      "    dec train predicted > ['three', 'one', 'one', 'one', 'one']\n",
      "\n",
      "\n",
      "Epoch 8:\n",
      "\n",
      "batch 8000\n",
      "  minibatch loss = 1.1053507328033447 | accuracy = 0.6274510025978088\n",
      "  sample 1:\n",
      "    enc input           > ['five', 'seven', 'three', 'three']\n",
      "    dec train predicted > ['five', 'three', 'three', 'three']\n",
      "  sample 2:\n",
      "    enc input           > ['six', 'four', 'six', 'five', 'ten']\n",
      "    dec train predicted > ['six', 'six', 'six', 'ten', 'ten']\n",
      "  sample 3:\n",
      "    enc input           > ['two', 'six', 'ten', 'six', 'four']\n",
      "    dec train predicted > ['two', 'six', 'six', 'six', 'six']\n",
      "\n",
      "\n",
      "Epoch 9:\n",
      "\n",
      "batch 9000\n",
      "  minibatch loss = 1.0035845041275024 | accuracy = 0.6041666865348816\n",
      "  sample 1:\n",
      "    enc input           > ['nine', 'nine', 'four', 'nine', 'four', 'two']\n",
      "    dec train predicted > ['nine', 'nine', 'nine', 'four', 'four', 'four']\n",
      "  sample 2:\n",
      "    enc input           > ['seven', 'four', 'eight', 'eight', 'two', 'two']\n",
      "    dec train predicted > ['seven', 'seven', 'two', 'two', 'two', 'two']\n",
      "  sample 3:\n",
      "    enc input           > ['eight', 'ten', 'four', 'four']\n",
      "    dec train predicted > ['eight', 'four', 'four', 'four']\n",
      "\n",
      "\n",
      "Epoch 10:\n",
      "\n",
      "batch 10000\n",
      "  minibatch loss = 1.0367146730422974 | accuracy = 0.5600000023841858\n",
      "  sample 1:\n",
      "    enc input           > ['nine', 'seven', 'five', 'one', 'nine', 'four', 'eight']\n",
      "    dec train predicted > ['nine', 'nine', 'nine', 'nine', 'four', 'four', 'ten']\n",
      "  sample 2:\n",
      "    enc input           > ['eight', 'four', 'three', 'six', 'eight', 'seven']\n",
      "    dec train predicted > ['eight', 'four', 'six', 'six', 'seven', 'seven']\n",
      "  sample 3:\n",
      "    enc input           > ['one', 'three', 'five']\n",
      "    dec train predicted > ['one', 'five', 'five']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pt.fit(train_iter=train_iter, indexer=indexer, num_epochs=10, batch_size=10, verbose=1000)\n",
    "    # Train it long enough you've get perfect results on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test: loss = 1.028043270111084 | accuracy = 0.5777559280395508\n"
     ]
    }
   ],
   "source": [
    "pt.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ended.\n"
     ]
    }
   ],
   "source": [
    "pt.end_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
